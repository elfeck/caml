%% Page 1, 2, 3
% Grid vs. pointbased approach of discretization
\section{Grid discretization}\label{sec:grid}

In machine learning, algorithms usually focus on a given training dataset
$X$, for instance
$$ X = \{x^{(i)} | \ x^{(i)} \in [0, 1]^d\}_{i = 1}^M \ , \ \ \
Y = \{y^{(i)} | \ y^{(i)} \in \mathbb{R}\}_{i=1}^M$$
with, in case of supervised learning, an associated solution set $Y$.

\par

\begin{figure*}[t!]
  \centering
  \input{images/figure_1.pgf}
  \caption{A function $f$, red, to be discretized.
    Seven grid points discretizing the space and their associated basis functions
  (left). By $\alpha_i$ weighted basis functions, dashed, and sum thereof (right)
  discretizing $f$.\label{fig:fig1}}
\end{figure*}

Grid-based approaches introduce an additional set $G$ of $N$
\emph{grid points} with
$$ G = \{1,2,\dots,N\} \ .$$
For each dimension of the feature space a separate $G$ (with possibly
different $N$) is constructed divinding the space into a grid.
This, by the grid \emph{discretized}, space
will then be used instead of working with the datapoints in the original
feature space directly.

% Gridpoints, Basis function, surplus, sum
% d > 1, tensor product
\subsection{Full grid discretization}\label{subsec:fullgrid}
In the following functions
will be restricted to the unit hypercube
 $$ f: [0, 1]^d \rightarrow \mathbb{R} \ .$$
To construct a \emph{full} grid we chose the grid points $G$ equidistant,
without grid points lying on the borders. \\
We first consider the case of a one-dimensional $f$ being discretized.
Around each gridpoint $i$ we center a one-dimensional
\emph{basis function}
$$ \phi_i(x) = \max\{0, 1 - |(N + 1)x - i|\} \ .$$
$\phi_i(x)$ is a standard hat function centered around $i$ and dilated
to have local support between the grid points $i - 1$ and $i + 1$. Fig.~\ref{fig:fig1}
shows $G = \{1,2,\dots,7\}$ and the related basis-functions.

\par

To discretize a function $f(x)$ we introduce a coefficient (surplus)
$\alpha_i$ for each grid point $i$. This coefficient is defined to be
$f$ evaluated at the grid point $i$
$$\alpha_i = f(\frac{i}{N+1}) \ .$$
Taking the sum
$$ f(x) \approx  \hat{f}(x) = \sum_{i \in G}{\alpha_i \phi_i(x)} $$
over all weighted basis-functions $\phi_i$ discretizes (approximates) $f$.
Fig.~\ref{fig:fig1} illustrates this.

\par

For $f(\vec{x})$ with $d > 1$, grid point representation is extended to
a $d$-tuple of indices, i.e. $(1,3,1)$ denoting the grid point with position
$x = 1, \ y = 3, \ z = 3$ in the dimensions $x,y,z$. \\
The related basis function
$$\phi_i(\vec{x}) = \prod_{j=1}^d{\phi_{i,j}(x_j)}$$
gets extended to $d$ dimensions using the tensor
product over the previously defined one-dimensional hat functions
$\phi_{i,j}(x_j)$ with $x_j$ being the $j$-th element of $\vec{x}$ and
$\phi_{i,j}$ denoting the basis-function of grid point $i$ in the dimension
$j$. To improve readability the dimension-related index $j$ of $\phi_{i,j}$
will be omitted in the following.

\subsection{Hierarchical basis}
Besides constructing the grid in the simple way as described in Sec.~\ref{subsec:fullgrid},
more sophisticated methods are available. In order to make a grid
sparse and still keep a sufficient accuracy the following
\emph{hierarchical basis} is introduced.
\par
We first examine the case $d = 1$.
Let $l \in \{1,2,\dots\}$ be the \emph{level} with $|G| = 2^{(l-1)}$ associated
grid points on each level. This level hierarchy groups grid points
into sets
$$G_l = \{i \in \mathbb{N} \ | \ 1 \leq \ i \leq 2^l, \ i \ \text{odd}\} \ ,$$
omitting every second grid point. Together the adjusted hat function
$$\phi_{l,i}(x) = \max\{0, 1 - |2^lx - i|\} \ $$
this forms the hierarchical basis in one dimension up to a level $n$.
By disregarding every
even grid point the local supports of basis functions on the \emph{same}
level are mutually exclusive and for each value of $x$ exactly one basis
function is not zero.
\par
Taking the weighted sum over all levels and all grid points in one dimension
$$ f(x) \approx \hat{f}(x) =  \sum_{l \leq n, i \in G_l}{\alpha_i\phi_{l,i}(x)}$$
discretizes f on a full grid. In contrast to the conventional approach from
Sec.~\ref{subsec:fullgrid} the hierarchical surpluses now are calculated using adjacent
gird points $i - 2$ and $i + 2$ such that
$$ \alpha_i = f\big(t(i)\big) - \frac{1}{2}\bigg(f\big(t(i - 2)\big) + f\big(t(i + 2)\big)\bigg) \ .$$
To transfer from grid-index $i$ with corresponding level $l$ to $x$
the function $t(i) = 2^{-l}i$ is used.
\par
For $d > 1$ we combine one the dimensional basis functions
to $d$ dimensional basis functions using the tensor product,
analogous to Sec.~\ref{subsec:fullgrid}. This is done for all possible combinations
of $l$ and $i$ in all dimensions as shown for $d = 2$ in FIGURE.
This process of building $d$-dimensional basis functions leads to a
hierarchy of subspaces which, summed up and weighted, discretize $f$.
\par
However, this does not lead to a sparse gird immediately. So far the
gridpoints only got regrouped and for a the maximum level $n$ this
results in $|G| = 2^{n} - 1$ basis functions for each dimension.
This further leads to an exponential dependency of the number of grid points
and $d$, thus having no effect on mitigating the curse of dimensionality.

%\begin{itemize}
%\item Basic notion
%\item Hierachial surplus
%\item Hierachial subspaces
%\end{itemize}


\begin{figure*}[t!]
  \centering
  \includegraphics{images/figure_2.png}
  \hspace{0cm}
  \includegraphics{images/figure_3.png}
  \caption{.\label{fig:fig2}}
\end{figure*}

\subsection{Sparse grid discretization}
In order to make the hierarchical grid \emph{sparse}, we now disregard certain
grid points with their associated subspaces defined by the
combinations of $\phi_{i,l}$ in $d$ dimensions. FIGURE illustrates this. \\
Which gridpoints contribute the least to the grid is a \emph{a-priori}
solvable optimization problem. Thus, independend of $f$ all $\phi_{(l,i)}$
related to the subspaces in the
lower right of the diagonal in FIGURE will be left out of the sum
$$\hat{f}(x) =  \sum_{l \leq n, i \in G_l}{\alpha_i\phi_{l,i}(x)}$$
from FIGURE.
%\begin{itemize}
%\item Disregarding subspaces
%\item Trade-off
%\item Spartial adaptivity
%\item Boundry and smoothness note
%\end{itemize}

%%% Local Variables:
%%% TeX-master: "report"
%%% End:
