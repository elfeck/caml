%% Page 1, 2, 3
% Grid vs. pointbased approach of discretization
\section{Grid discretization}\label{sec:grid}

In machine learning, algorithms usually focus on a given training dataset
$X$, for instance
$$ X = \{x^{(i)} | \ x^{(i)} \in [0, 1]^d\}_{i = 1}^M \ , \ \ \
Y = \{y^{(i)} | \ y^{(i)} \in \mathbb{R}\}_{i=1}^M$$
with, in case of supervised learning, an associated solution set $Y$.

\par

\begin{figure*}[t!]
  \centering
  \input{images/figure_1_1.pgf}
  \input{images/figure_1_2.pgf}
  \input{images/figure_1_3.pgf}
  \caption{A function $f$, red, to be discretized.
    Seven grid points discretizing the space
    (left). Full grid discretization by nodal basis (middle) and
    hierarchical basis, scaled by $\alpha_i$ and $\alpha_{l,i}$
    respectively (right).\label{fig:fig1}}
\end{figure*}

Grid-based approaches introduce an additional set $G$ of $N$
\emph{grid points} with
$$ G = \{1,2,\dots,N\} \ .$$
For each dimension of the feature space a separate $G$ (with possibly
different $N$) is constructed divinding the space into a grid.
This, by the grid \emph{discretized}, space
will then be used instead of working with the datapoints in the original
feature space directly.

% Gridpoints, Basis function, surplus, sum
% d > 1, tensor product
\subsection{Full grid discretization}\label{subsec:fullgrid}
In the following functions
will be restricted to the unit hypercube
 $$ f: [0, 1]^d \rightarrow \mathbb{R} \ .$$
To construct a \emph{full} grid we chose the grid points $G$ equidistant,
without grid points lying on the borders. \\
We first consider the case of a one-dimensional $f$ being discretized.
Around each gridpoint $i$ we center a one-dimensional
\emph{basis function}
$$ \phi_i(x) = \max\{0, 1 - |(N + 1)x - i|\} \ .$$
$\phi_i(x)$ is a standard hat function centered around $i$ and dilated
to have local support between the grid points $i - 1$ and $i + 1$. Fig.~\ref{fig:fig1}
shows $G = \{1,2,\dots,7\}$ and the related basis-functions.

\par

To discretize a function $f(x)$ we introduce a coefficient (surplus)
$\alpha_i$ for each grid point $i$. This coefficient is defined to be
$f$ evaluated at the grid point $i$
$$\alpha_i = f(\frac{i}{N+1}) \ .$$
Taking the sum
$$ f(x) \approx  \hat{f}(x) = \sum_{i \in G}{\alpha_i \phi_i(x)} $$
over all weighted basis-functions $\phi_i$ discretizes (approximates) $f$.
Fig.~\ref{fig:fig1} illustrates this.

\par

For $f(\vec{x})$ with $d > 1$, grid point representation is extended to
a $d$-tuple of indices, i.e. $(1,3,1)$ denoting the grid point with position
$x = 1, \ y = 3, \ z = 3$ in the dimensions $x,y,z$. \\
The related basis function
$$\phi_i(\vec{x}) = \prod_{j=1}^d{\phi_{i,j}(x_j)}$$
gets extended to $d$ dimensions using the tensor
product over the previously defined one-dimensional hat functions
$\phi_{i,j}(x_j)$ with $x_j$ being the $j$-th element of $\vec{x}$ and
$\phi_{i,j}$ denoting the basis-function of grid point $i$ in the dimension
$j$. To improve readability the dimension-related index $j$ of $\phi_{i,j}$
will be omitted in the following.

\subsection{Hierarchical basis}
Besides constructing the grid in the simple way described in Sec.~\ref{subsec:fullgrid},
more sophisticated methods are available. In order to make a grid
sparse and still keep a sufficient accuracy the following
\emph{hierarchical basis} is introduced.
\par
We first examine the case $d = 1$.
Let $l \in \{1,2,\dots\}$ be the \emph{level} with $|G| = 2^{(l-1)}$ associated
grid points on each level. This level hierarchy groups grid points
into sets
$$G_l = \{i \in \mathbb{N} \ | \ 1 \leq \ i \leq 2^l, \ i \ \text{odd}\} \ ,$$
omitting every second grid point. Together the adjusted hat function
$$\phi_{l,i}(x) = \max\{0, 1 - |2^lx - i|\} \ $$
this forms the hierarchical basis in one dimension up to a level $n$.
By disregarding every
even grid point the local supports of basis functions on the \emph{same}
level are mutually exclusive and for each value of $x$ exactly one basis
function is not zero. \\
A grid point is now referred to as grid point in the level $l$ with index $i$.
Note, that the indices alone do not uniquely define a grid point (i.e. grid
points of index $i = 1$ are element in every $G_l$). The same applies to
the corresponding $\phi$ and $\alpha$.
\par
Taking the weighted sum over all levels and all grid points in one dimension
$$ f(x) \approx \hat{f}(x) =  \sum_{l \leq n, i \in G_l}{\alpha_{l,i}\phi_{l,i}(x)}$$
discretizes f on a full grid.

In contrast to the conventional approach from
Sec.~\ref{subsec:fullgrid} the surpluses now are calculated
differently.
Let $x_{l,i}$ be the $x$-value of the grid point given by $l$ and $i$. Then
$$a_{l,i} = f(x_{l,i}) - \frac{f(x_{l,i} - 2^{-l}) + f(x_{l,i} + 2^{-l})}{2}$$
is the \emph{hierarchical surplus} for the grid point $(l,i)$. The function
value at the grid point is taken and the function values
at neighbouring grid points are subtracted (``neighbouring''
is disregarding $l$). For instance, for $\alpha_{2,1}$ we get $x_{2,1} =
\frac{1}{4}$ and
$$\alpha_{2,1} = f\Big(\frac{1}{4}\Big) - \frac{f\Big(\frac{1}{4} - 2^{-2}\Big) - f\Big(\frac{1}{4} + 2^{-2}\Big)}{2} \ .$$
\par
For $d > 1$ we combine the one dimensional basis functions
to $d$-dimensional basis functions using the tensor product,
analogous to Sec.~\ref{subsec:fullgrid}. This is done for all possible combinations
of $l$ and $i$ in all dimensions.
This process of building $d$-dimensional basis functions
through combining over the level in different dimensions leads to a
subspaces defined by the level-vector $\vec{l} = {l_x, l_y, \dots}$
as shown for $d = 2$ in Fig.~\ref{fig:fig2}. \\
Taking the sum $\sum_{l,i} \alpha_{l,i}\phi_{l,i}(x)$ over all
$$\phi_{l,i}(\vec{x}) = \prod_j^d{\phi_{l,i,j}(x_j)}$$
discretizes $f(\vec{x})$ on a hierarchical structured grid.
\par
However, this does not lead to a sparse gird immediately. So far the
gridpoints only got regrouped and for a the maximum level $n$ this
results in $|G| = 2^{n} - 1$ basis functions for each dimension.
This further leads to an exponential dependency of the number of grid points
and $d$, thus having no effect on mitigating the curse of dimensionality.

%\begin{itemize}
%\item Basic notion
%\item Hierachial surplus
%\item Hierachial subspaces
%\end{itemize}


\begin{figure*}[t!]
  \centering
  \includegraphics{images/figure_2.png}
  \includegraphics{images/figure_3.png}
  \caption{Hierarchical subspaces (left) and corresponding grid points
    (right) ($d = 2$) with the last column being the complete sparse grid.
    For the sparse grid omitted subspaces/grid points in grey.
    \label{fig:fig2}}
\end{figure*}

\subsection{Sparse grid discretization}
In order to make the hierarchical grid \emph{sparse}, we now disregard certain
subspaces with their associated  grid points. The goal is to reduced the total
number of grid points by finding and disregarding those that contribute the
least to the discretization of $f$.
Which gridpoints that are is a \emph{a-priori}
solvable optimization problem. Thus, independent of $f$ all $\phi_{l,i}$
related to the subspaces in the
lower right of the diagonal in Fig.~\ref{fig:fig2} will be left out of the sum
$$\hat{f}(x) =  \sum_{l \leq n, i \in G_l}{\alpha_i\phi_{l,i}(x)}$$
from Sec.~\ref{subsec:fullgrid}.
\par
By doing so, we reduced the total number of grid points drastically
from $\mathcal{O}(2^{nd})$ to $\mathcal{O}(2^{n} \cdot n^{d-1})$ where $n$ is
the maximal level in the hierarchical structure. The asymptotic error on the
other hand only slightly increases from $\mathcal{O}(2^{-2n})$ to
\mbox{$\mathcal{O}(2^{-2n} \cdot n^{d-1})$}. Tab.~\ref{tab:tab1}
illustrates the quickly
growing gap between the number of grid points in a full and sparse grid.
\begin{table}[h]
  \centering
  \begin{tabular}{r | c | c | c | c | c | c}
    d & 1 & 2 & 3 & 5 & 10 & 20 \\
    \hline\hline
    Full & 15 &  225 & 3375 & $>10^5$ & $> 10^{11}$ & $> 10^{23}$ \\
    \hline
    Sparse & 15 & 49 & 111 & 351 & 2001 & 13201 \\
  \end{tabular}
  \captionsetup{width=0.44\textwidth}
  \caption{Number of grid points in a full and sparse grid
    (without points on the boundaries)
    with maximal level $n = 4$ and growing dimension $d$.\label{tab:tab1}}
\end{table}\\
It is important to note that the numbers in Tab.~\ref{tab:tab1} are taken
for a sparse grid without points on the boundaries. In case the function
to be discretized is not zero on the boundaries, such points become necessary.
Treatment of the boundaries might require considerably
more grid points. For further information please refer to REF.
%Tab.~\ref{tab:tab1} also shows that sparse grids are not capable to fully
%counteract the Curse of Dimensionality. Still, sparse grids provide a tool
%to mitigate the problem and and make previously impossible tasks manageable.

\subsection{Adaptive sparse grids}

%\begin{itemize}
%\item Disregarding subspaces
%\item Trade-off
%\item Spartial adaptivity
%\item Boundry and smoothness note
%\end{itemize}

%%% Local Variables:
%%% TeX-master: "report"
%%% End:
